{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentdex - deep learning 01",
      "provenance": [],
      "collapsed_sections": [
        "uLILZ-ZfIQ_m",
        "KGrvjy-iJP3h",
        "giC03radQg5M"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jo-cho/memos/blob/master/RL/sentdex_deep_learning_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLILZ-ZfIQ_m",
        "colab_type": "text"
      },
      "source": [
        "## get Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jLInUvAb2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY5bDLhmHs2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82301b59-0555-4662-daeb-1e2f4cb944f1"
      },
      "source": [
        "x = torch.Tensor([5,3])\n",
        "y = torch.Tensor([2,1])\n",
        "\n",
        "print(x*y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10.,  3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYuKNbwxIMhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "854703eb-a140-42ed-85d1-86dd85278587"
      },
      "source": [
        "x = torch.zeros([2,5])\n",
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGRDeJZRIZZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "228ffd44-38f9-443f-b579-b142bfe1ff6f"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0NqSbaQIajo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6583be27-1ec0-4400-c333-531e44bd1ba9"
      },
      "source": [
        "y = torch.rand([2,5])\n",
        "y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0979, 0.7449, 0.7770, 0.6545, 0.4143],\n",
              "        [0.8608, 0.9742, 0.5075, 0.3356, 0.8097]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7MXA8WkIjfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a71e6a0a-bc35-4d70-d20d-c13877f6861d"
      },
      "source": [
        "y.view([1,10]) #reshape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0979, 0.7449, 0.7770, 0.6545, 0.4143, 0.8608, 0.9742, 0.5075, 0.3356,\n",
              "         0.8097]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrl854qlI5lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0867c7bd-ab5e-4ae9-cba6-79e7ca93e503"
      },
      "source": [
        "y = y.view([1,10])\n",
        "y"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0979, 0.7449, 0.7770, 0.6545, 0.4143, 0.8608, 0.9742, 0.5075, 0.3356,\n",
              "         0.8097]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLIBDYE9IfsG",
        "colab_type": "text"
      },
      "source": [
        "It's similar to numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGrvjy-iJP3h",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxpAULn_I3Uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "#for training for visioning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo6K_XdnJxZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "b5ca9a2a-3e7f-4893-c31f-8016b59b2543"
      },
      "source": [
        "train = datasets.MNIST(\"\", train=True, download= True, \n",
        "                       transform= transforms.Compose([transforms.ToTensor()])) \n",
        "\n",
        "test = datasets.MNIST(\"\", train=False, download= True, \n",
        "                       transform= transforms.Compose([transforms.ToTensor()])) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:02, 3912232.04it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 57880.41it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:01, 952113.98it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 21593.56it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75wE1eV8MtBm",
        "colab_type": "text"
      },
      "source": [
        "training and testing data split\n",
        "\n",
        "- To train any machine learning model, we want to first off have training and validation datasets. This is so we can use data that the machine has never seen before to \"test\" the machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itq5GOn-K-Dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torch.utils.data.DataLoader(train,batch_size=10, shuffle=True)\n",
        "testset = torch.utils.data.DataLoader(test,batch_size=10, shuffle=True)\n",
        "\n",
        "# What is a batch?\n",
        "# Why shuffle? --> this data is hand-write digit. generalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozsDX32cNVVy",
        "colab_type": "text"
      },
      "source": [
        "iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmFjAnKBNU23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "da89d58c-2f69-4831-b488-bfb107ddf62a"
      },
      "source": [
        "for data in trainset:\n",
        "    print(data)\n",
        "    break #too many"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([4, 3, 9, 1, 2, 8, 1, 5, 2, 8])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrOZZZKANqUa",
        "colab_type": "text"
      },
      "source": [
        "Each iteration will contain a batch of 10 elements (that was the batch size we chose), and 10 classes. Let's just look at one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9SDvidINvm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = data[0][0], data[1][0]\n",
        "# X는 input data (features) y는 label\n",
        "# X는 image matrix\n",
        "# y는 숫자"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb2uhd3yOB1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0d9b443-9af5-4122-d662-a4927859ab01"
      },
      "source": [
        "print(data[1]) #targets"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4, 3, 9, 1, 2, 8, 1, 5, 2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcmwd9U-PByd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9898e905-77e2-496f-9bff-aae9862d4ac8"
      },
      "source": [
        "# image shape be like\n",
        "print(data[0][0].shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkPH5LYkOHod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cd137dfa-d0a0-4dbf-cc91-0c0f45a0205c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(data[0][0].view(28,28)) #to show, reshape해야 함.\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ynfuE2PYgh",
        "colab_type": "text"
      },
      "source": [
        "Balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQyzLu5LP9qp",
        "colab_type": "text"
      },
      "source": [
        "iterate over everything and make a count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX8FdexrPhJy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "5f7c428e-a96b-4f38-f264-4f9e592adcbd"
      },
      "source": [
        "#example\n",
        "\n",
        "total = 0\n",
        "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
        "\n",
        "\n",
        "for data in trainset:\n",
        "    Xs, ys = data\n",
        "    for y in ys:\n",
        "        counter_dict[int(y)] += 1\n",
        "        total += 1\n",
        "\n",
        "print(counter_dict)\n",
        "\n",
        "for i in counter_dict:\n",
        "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
            "0: 9.871666666666666%\n",
            "1: 11.236666666666666%\n",
            "2: 9.93%\n",
            "3: 10.218333333333334%\n",
            "4: 9.736666666666666%\n",
            "5: 9.035%\n",
            "6: 9.863333333333333%\n",
            "7: 10.441666666666666%\n",
            "8: 9.751666666666667%\n",
            "9: 9.915000000000001%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giC03radQg5M",
        "colab_type": "text"
      },
      "source": [
        "## Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekBzOgNCQgPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn  as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZUDoGusQoj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e0a0987b-fa3f-4066-935c-9dbac6f2a708"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()              # to aviod the errors\n",
        "        self.fc1 = nn.Linear(28*28, 64) # (input,output-hiddenlayer)\n",
        "        self.fc2 = nn.Linear(64, 64)    # hidden\n",
        "        self.fc3 = nn.Linear(64, 64)    # hidden\n",
        "        self.fc4 = nn.Linear(64, 10)    # (we have 10 classes. 마지막 ouput)\n",
        "\n",
        "   # def forward(self, x):\n",
        "   #     x = self.fc1(x)\n",
        "   #     x = self.fc2(x)\n",
        "   #     x = self.fc3(x)\n",
        "   #     x = self.fc4(x)\n",
        "   #     return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "    # Currently, the most popular is the rectified linear, or relu, activation function.\n",
        "    # Basically, these activation functions are keeping our data scaled between 0 and 1.\n",
        "    # pytorch를 쓴 이유\n",
        "    \n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82m0Yc-zR_b5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이해를 위한 예시\n",
        "\n",
        "x = torch.rand((28,28))\n",
        "x = x.view(-1,28*28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qGmaSs2TRm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4948c21-f256-401d-c9d4-c291b256a32b"
      },
      "source": [
        "x"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2251, 0.0049, 0.1916, 0.1025, 0.5782, 0.4445, 0.9565, 0.0127, 0.8727,\n",
              "         0.5016, 0.2550, 0.2391, 0.0929, 0.1938, 0.5101, 0.7392, 0.0907, 0.7442,\n",
              "         0.2985, 0.2371, 0.9524, 0.5033, 0.2326, 0.2127, 0.4390, 0.7195, 0.6652,\n",
              "         0.3725, 0.1160, 0.0459, 0.9759, 0.9762, 0.4202, 0.5420, 0.8283, 0.8606,\n",
              "         0.3174, 0.2077, 0.5491, 0.7115, 0.1855, 0.9359, 0.5511, 0.3241, 0.3421,\n",
              "         0.0181, 0.9323, 0.0807, 0.0630, 0.2734, 0.5347, 0.0657, 0.6815, 0.9564,\n",
              "         0.5118, 0.7310, 0.1879, 0.7718, 0.7116, 0.3537, 0.4096, 0.6826, 0.0781,\n",
              "         0.6945, 0.1794, 0.0640, 0.3415, 0.7175, 0.7275, 0.8838, 0.4966, 0.3895,\n",
              "         0.7193, 0.3646, 0.4345, 0.0228, 0.3439, 0.7021, 0.9180, 0.2026, 0.5228,\n",
              "         0.9862, 0.8476, 0.5943, 0.3227, 0.9251, 0.7720, 0.6222, 0.1404, 0.1562,\n",
              "         0.4205, 0.4880, 0.6037, 0.4177, 0.2055, 0.6013, 0.4590, 0.9214, 0.4725,\n",
              "         0.7239, 0.9447, 0.5042, 0.5423, 0.8521, 0.0644, 0.4721, 0.1015, 0.1290,\n",
              "         0.4068, 0.8085, 0.1709, 0.8061, 0.2867, 0.7401, 0.6108, 0.9718, 0.3050,\n",
              "         0.9016, 0.0156, 0.9614, 0.4969, 0.1228, 0.0850, 0.0170, 0.9551, 0.7649,\n",
              "         0.4804, 0.7125, 0.0851, 0.7339, 0.4508, 0.0125, 0.0816, 0.1165, 0.6879,\n",
              "         0.8707, 0.2702, 0.8540, 0.1487, 0.9749, 0.8166, 0.1984, 0.1611, 0.1183,\n",
              "         0.1747, 0.3487, 0.7295, 0.6212, 0.0436, 0.0731, 0.0273, 0.1687, 0.2687,\n",
              "         0.6108, 0.3555, 0.5099, 0.1169, 0.6604, 0.7435, 0.1898, 0.8367, 0.4425,\n",
              "         0.3452, 0.5921, 0.1736, 0.2584, 0.8784, 0.1769, 0.9035, 0.9672, 0.9977,\n",
              "         0.8417, 0.2856, 0.4067, 0.2488, 0.9822, 0.0625, 0.6320, 0.7542, 0.9447,\n",
              "         0.2693, 0.0978, 0.4869, 0.2726, 0.9424, 0.4602, 0.2604, 0.5553, 0.4655,\n",
              "         0.1046, 0.0543, 0.3448, 0.6564, 0.6275, 0.0464, 0.0685, 0.3579, 0.3848,\n",
              "         0.2421, 0.1296, 0.4273, 0.9549, 0.0981, 0.2926, 0.0161, 0.1030, 0.8825,\n",
              "         0.1380, 0.4045, 0.2557, 0.7462, 0.6891, 0.1050, 0.6179, 0.9395, 0.0022,\n",
              "         0.2405, 0.0525, 0.5470, 0.3327, 0.3916, 0.9585, 0.4956, 0.6921, 0.6367,\n",
              "         0.4609, 0.0721, 0.0710, 0.7431, 0.4197, 0.4732, 0.2400, 0.7269, 0.5724,\n",
              "         0.8081, 0.0380, 0.8518, 0.9126, 0.8628, 0.5449, 0.1764, 0.1787, 0.5055,\n",
              "         0.4274, 0.3213, 0.1477, 0.5575, 0.0788, 0.1019, 0.8899, 0.7274, 0.2392,\n",
              "         0.0170, 0.3552, 0.0108, 0.6923, 0.9988, 0.0029, 0.4463, 0.8309, 0.5766,\n",
              "         0.0596, 0.1335, 0.8989, 0.9008, 0.5809, 0.9595, 0.0440, 0.1864, 0.9959,\n",
              "         0.6528, 0.1087, 0.1150, 0.9423, 0.9872, 0.5773, 0.9738, 0.8183, 0.6330,\n",
              "         0.8226, 0.0924, 0.6629, 0.8337, 0.7096, 0.4836, 0.3689, 0.1700, 0.9428,\n",
              "         0.0130, 0.4361, 0.7668, 0.3399, 0.2985, 0.5698, 0.4855, 0.8425, 0.7272,\n",
              "         0.8107, 0.3582, 0.1932, 0.2853, 0.4452, 0.8623, 0.5675, 0.6638, 0.6684,\n",
              "         0.3088, 0.5018, 0.0035, 0.9007, 0.2145, 0.7927, 0.0325, 0.6593, 0.6612,\n",
              "         0.6478, 0.2717, 0.8975, 0.5300, 0.8314, 0.8422, 0.5345, 0.3441, 0.7500,\n",
              "         0.5047, 0.8269, 0.9057, 0.6737, 0.4965, 0.1736, 0.7696, 0.0838, 0.2887,\n",
              "         0.2380, 0.6140, 0.8689, 0.7866, 0.2235, 0.7522, 0.3823, 0.0897, 0.7032,\n",
              "         0.2442, 0.5978, 0.2861, 0.4986, 0.7593, 0.8628, 0.4624, 0.3073, 0.7948,\n",
              "         0.1948, 0.3387, 0.1468, 0.7124, 0.7756, 0.0299, 0.1302, 0.1203, 0.1205,\n",
              "         0.6599, 0.2560, 0.5162, 0.9864, 0.2888, 0.2729, 0.8118, 0.1618, 0.9278,\n",
              "         0.1609, 0.6230, 0.5114, 0.3397, 0.0840, 0.0979, 0.1792, 0.4220, 0.5024,\n",
              "         0.5263, 0.4193, 0.8487, 0.4618, 0.1609, 0.8271, 0.9901, 0.0953, 0.0088,\n",
              "         0.9641, 0.1483, 0.4225, 0.6097, 0.0531, 0.9030, 0.7447, 0.9087, 0.9767,\n",
              "         0.6309, 0.9422, 0.6441, 0.2165, 0.5764, 0.5141, 0.5159, 0.6227, 0.6649,\n",
              "         0.1854, 0.6510, 0.1990, 0.4352, 0.2084, 0.8540, 0.8884, 0.1533, 0.7320,\n",
              "         0.0702, 0.0099, 0.3342, 0.1714, 0.2097, 0.1885, 0.0196, 0.0113, 0.9932,\n",
              "         0.8141, 0.8129, 0.7948, 0.7036, 0.0326, 0.6515, 0.7357, 0.1241, 0.1740,\n",
              "         0.4846, 0.1261, 0.1023, 0.7439, 0.7880, 0.8476, 0.0537, 0.5978, 0.2351,\n",
              "         0.0757, 0.8220, 0.3531, 0.2312, 0.4925, 0.5640, 0.2286, 0.4448, 0.0276,\n",
              "         0.2381, 0.7045, 0.0349, 0.1531, 0.0919, 0.1673, 0.4219, 0.0516, 0.1613,\n",
              "         0.7639, 0.6327, 0.6393, 0.7009, 0.9564, 0.0160, 0.9955, 0.2731, 0.6463,\n",
              "         0.4953, 0.7762, 0.8174, 0.2417, 0.2795, 0.6282, 0.8380, 0.0573, 0.9351,\n",
              "         0.4245, 0.8344, 0.1513, 0.8357, 0.9049, 0.9091, 0.9688, 0.6644, 0.9148,\n",
              "         0.8039, 0.5511, 0.1716, 0.9087, 0.4349, 0.2041, 0.5041, 0.7602, 0.8887,\n",
              "         0.2179, 0.3493, 0.9575, 0.2556, 0.1946, 0.1555, 0.8615, 0.1227, 0.5834,\n",
              "         0.9588, 0.3060, 0.4383, 0.4385, 0.6678, 0.2722, 0.4051, 0.0576, 0.2394,\n",
              "         0.0426, 0.5797, 0.1085, 0.9446, 0.3599, 0.7689, 0.5705, 0.1779, 0.0116,\n",
              "         0.5078, 0.4351, 0.9718, 0.2024, 0.7035, 0.5206, 0.0389, 0.4050, 0.2541,\n",
              "         0.6864, 0.3089, 0.2716, 0.8078, 0.0112, 0.6189, 0.5483, 0.3844, 0.2704,\n",
              "         0.6112, 0.4817, 0.8726, 0.3270, 0.8565, 0.3380, 0.2279, 0.4870, 0.3727,\n",
              "         0.8417, 0.2504, 0.9775, 0.4496, 0.8936, 0.1938, 0.8668, 0.6821, 0.7006,\n",
              "         0.5790, 0.9348, 0.2142, 0.5339, 0.9420, 0.3898, 0.4841, 0.4167, 0.4170,\n",
              "         0.2252, 0.4591, 0.0941, 0.9540, 0.6399, 0.6761, 0.6852, 0.7148, 0.8877,\n",
              "         0.6703, 0.0679, 0.0568, 0.2500, 0.7451, 0.9970, 0.3280, 0.8632, 0.9709,\n",
              "         0.8631, 0.9371, 0.3707, 0.0713, 0.5094, 0.7319, 0.4888, 0.6559, 0.2802,\n",
              "         0.9243, 0.0308, 0.2253, 0.3444, 0.6970, 0.6782, 0.1487, 0.7950, 0.7026,\n",
              "         0.8445, 0.4512, 0.6882, 0.8529, 0.5304, 0.3707, 0.0190, 0.9574, 0.0845,\n",
              "         0.6604, 0.0958, 0.8971, 0.2238, 0.5999, 0.5771, 0.5416, 0.1494, 0.0164,\n",
              "         0.3365, 0.5026, 0.3946, 0.7721, 0.0949, 0.4812, 0.8901, 0.6169, 0.5684,\n",
              "         0.6228, 0.2340, 0.3808, 0.5890, 0.6553, 0.6401, 0.7452, 0.4306, 0.1707,\n",
              "         0.0130, 0.6131, 0.6843, 0.2818, 0.7367, 0.8611, 0.9121, 0.0117, 0.0677,\n",
              "         0.1658, 0.2809, 0.9523, 0.9796, 0.0695, 0.0731, 0.1764, 0.3035, 0.1706,\n",
              "         0.4578, 0.4617, 0.7844, 0.7081, 0.4037, 0.0482, 0.2029, 0.2218, 0.3695,\n",
              "         0.9123, 0.4176, 0.5822, 0.1238, 0.7350, 0.9372, 0.3158, 0.5311, 0.0325,\n",
              "         0.6530, 0.0537, 0.3455, 0.5934, 0.8417, 0.2160, 0.1641, 0.5039, 0.0674,\n",
              "         0.6912, 0.6463, 0.1385, 0.2047, 0.7910, 0.4570, 0.0601, 0.9849, 0.6625,\n",
              "         0.0023, 0.8975, 0.7152, 0.7862, 0.0401, 0.3065, 0.8880, 0.0031, 0.5614,\n",
              "         0.9307, 0.4938, 0.5339, 0.5645, 0.6007, 0.1097, 0.5260, 0.6709, 0.3513,\n",
              "         0.1709, 0.2132, 0.6618, 0.7098, 0.9971, 0.5697, 0.2895, 0.1812, 0.5197,\n",
              "         0.7150, 0.2215, 0.1002, 0.7032, 0.1895, 0.8322, 0.8381, 0.5035, 0.2171,\n",
              "         0.6678, 0.6196, 0.4306, 0.1826, 0.9951, 0.3316, 0.5398, 0.7785, 0.2149,\n",
              "         0.6198, 0.9544, 0.9929, 0.1749, 0.3792, 0.6568, 0.2477, 0.5358, 0.7161,\n",
              "         0.8865, 0.9844, 0.4053, 0.6701, 0.8972, 0.5696, 0.3873, 0.4340, 0.7132,\n",
              "         0.3879, 0.8101, 0.7851, 0.8711, 0.5811, 0.4063, 0.4897, 0.5967, 0.6133,\n",
              "         0.5126, 0.4434, 0.4136, 0.1877, 0.1170, 0.5945, 0.2834, 0.5766, 0.2365,\n",
              "         0.6513, 0.3931, 0.5167, 0.1668, 0.4810, 0.2836, 0.7018, 0.0840, 0.6499,\n",
              "         0.9465]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd2rbMC5TYAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d8e5656e-32a1-4963-eba3-324e37103188"
      },
      "source": [
        "output = net(x)\n",
        "output"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.3017, -2.2334, -2.3295, -2.1728, -2.1871, -2.3154, -2.3217, -2.4331,\n",
              "         -2.3408, -2.4252]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoJt-yK1T8MZ",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxvpkHPxVz1j",
        "colab_type": "text"
      },
      "source": [
        "we want to calculate loss and specify our optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pTLsQIMUAGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001) #lr = learning rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhFW8DXhZfej",
        "colab_type": "text"
      },
      "source": [
        "For simpler tasks, a learning rate of 0.001 usually is more than fine. For more complex tasks, you will see a learning rate with what's called a decay. Basically you start the learning rate at something like 0.001, or 0.01...etc, and then over time, that learning rate gets smaller and smaller. The idea being you can initially train fast, and slowly take smaller steps, hopefully getthing the best of both worlds:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN5AD28UV2Hi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e8af249-a150-4176-ebf4-1c6252d087c2"
      },
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for data in trainset:\n",
        "    # data is a batch of featuresets and labels\n",
        "    X, y = data\n",
        "    print(X[0])\n",
        "    print(y[0])\n",
        "    break"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.4157, 0.8980, 1.0000, 0.3490,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0235, 0.6549, 0.9176, 0.9843, 0.9922, 0.7137, 0.2157,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0431, 0.6275, 0.9922, 0.9922, 0.8863, 0.5490, 0.0431, 0.0000,\n",
            "          0.0000, 0.0000, 0.1216, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1647,\n",
            "          0.6157, 0.9922, 0.9922, 0.8980, 0.2118, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.3725, 0.8510, 0.9137, 0.1608, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7529,\n",
            "          0.9922, 0.9922, 0.6431, 0.1804, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0196, 0.8314, 0.9922, 0.9922, 0.2118, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2078, 0.8980,\n",
            "          0.9922, 0.9294, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0275, 0.9922, 0.9922, 0.9922, 0.2118, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.9176, 0.9922,\n",
            "          0.9216, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3098, 0.9922, 0.9922, 0.8235, 0.1059, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.9255, 0.9922,\n",
            "          0.8588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.7843,\n",
            "          0.9843, 0.9922, 0.9922, 0.6667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8353, 0.9922,\n",
            "          0.9804, 0.8902, 0.8902, 0.8902, 0.8902, 0.8902, 0.9647, 0.9922,\n",
            "          0.9922, 0.9922, 0.9922, 0.6667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9294,\n",
            "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9922, 0.8824, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2039,\n",
            "          0.6314, 0.8039, 0.8039, 0.8039, 0.8039, 0.6549, 0.4039, 0.9922,\n",
            "          0.9922, 0.9922, 0.5882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9922,\n",
            "          0.9922, 0.9412, 0.2353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2039, 0.9922,\n",
            "          0.9922, 0.4980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7294, 0.9922,\n",
            "          0.9647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7294, 0.9922,\n",
            "          0.9647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7294, 0.9922,\n",
            "          0.9647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7294, 0.9922,\n",
            "          0.9647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 0.9922,\n",
            "          0.9843, 0.4392, 0.1647, 0.1647, 0.1647, 0.0510, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.9647,\n",
            "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.6275, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980,\n",
            "          0.7451, 0.4549, 0.4549, 0.4549, 0.4549, 0.3804, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
            "tensor(9)\n",
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0784, 0.4745, 0.7725, 0.9922, 0.7490,\n",
            "          0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.2000, 0.9490, 0.9882, 0.9882, 0.9882, 0.9922,\n",
            "          0.7216, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0980, 0.7725, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922,\n",
            "          0.9882, 0.8980, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.7020, 0.9882, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.7725, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.2510, 0.9451, 0.9882, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.9882, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3176, 0.9882, 0.9882, 0.9882, 0.8000, 0.5686, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.9216, 0.1647, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3176, 0.9882, 0.9882, 0.9882, 0.3647, 0.0549, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.6745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.2824, 0.9647, 0.9882, 0.9882, 0.7569, 0.6471, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.7569, 0.9882, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.1255, 0.8510, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.1137, 0.8471, 0.9922, 0.9922, 0.9922, 1.0000,\n",
            "          0.9922, 0.9922, 0.8275, 0.3490, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.6784, 0.9882, 0.9882, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.9882, 0.8353, 0.1098, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.1922, 0.9569, 0.9882, 0.9882, 0.9882, 0.8196,\n",
            "          0.9686, 0.9882, 0.9882, 0.9882, 0.2588, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.2118, 0.9882, 0.9882, 0.9882, 0.8196, 0.0824,\n",
            "          0.1451, 0.9020, 0.9882, 0.9882, 0.5333, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.2118, 0.9882, 0.9882, 0.9451, 0.0980, 0.0000,\n",
            "          0.0000, 0.8863, 0.9882, 0.9882, 0.2588, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.5961, 0.9882, 0.9882, 0.9333, 0.0000, 0.0000,\n",
            "          0.4235, 0.9608, 0.9882, 0.9882, 0.2588, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.3765, 0.9882, 0.9882, 0.9725, 0.4039, 0.4078,\n",
            "          0.9725, 0.9882, 0.9882, 0.9882, 0.2588, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.2118, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.9882, 0.7647, 0.0941, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0902, 0.7725, 0.9686, 0.9882, 0.9882, 0.9922,\n",
            "          0.9882, 0.9882, 0.8039, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.3529, 0.9882, 0.9882, 0.9922,\n",
            "          0.9882, 0.7922, 0.3216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
            "tensor(8)\n",
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.1373, 0.4235, 0.4235, 0.3569, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765,\n",
            "          0.3686, 0.3686, 0.8431, 0.9922, 0.9922, 0.9765, 0.8353, 0.1569,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.2039, 0.6196, 0.8392, 0.9176,\n",
            "          0.9922, 0.7098, 0.6784, 0.6784, 0.6784, 0.7255, 0.9922, 0.8745,\n",
            "          0.1490, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0588, 0.3490, 0.9176, 0.9922, 0.9922, 0.8745,\n",
            "          0.2314, 0.0235, 0.0000, 0.0000, 0.0000, 0.0353, 0.2627, 0.8824,\n",
            "          0.8824, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.1686, 0.6549, 0.9922, 0.9922, 0.9804, 0.5020, 0.1373,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5765,\n",
            "          0.9922, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3020, 0.9294, 0.9608, 0.8588, 0.8353, 0.2941, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8627,\n",
            "          0.6314, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2353,\n",
            "          0.9373, 0.9922, 0.7255, 0.0588, 0.1333, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.4784, 0.9882,\n",
            "          0.4196, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.6784,\n",
            "          0.9922, 0.5333, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1608, 0.9922, 0.9137,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6980, 0.9922,\n",
            "          0.8275, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4392, 0.9922, 0.4196,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9490, 0.9961,\n",
            "          0.4353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.4627, 1.0000, 0.6431, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4549, 0.9922, 0.6431,\n",
            "          0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.1373, 0.8353, 0.9804, 0.8431, 0.0196, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9451, 0.9922, 0.6235,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.3333, 0.8431, 0.9922, 0.6078, 0.0863, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9961, 0.9922, 0.6235,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529,\n",
            "          0.5373, 0.9765, 0.8941, 0.5373, 0.0431, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8588, 0.9922, 0.6235,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.2667, 0.6118,\n",
            "          0.9922, 0.9922, 0.5373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3765, 0.9843, 0.8980,\n",
            "          0.2941, 0.0471, 0.0000, 0.1451, 0.2118, 0.5294, 0.9922, 0.9961,\n",
            "          0.7922, 0.3137, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9451, 0.9922,\n",
            "          0.9922, 0.7451, 0.6824, 0.8941, 0.9922, 0.9922, 0.9098, 0.5882,\n",
            "          0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3490, 0.8353,\n",
            "          0.9216, 0.9922, 0.9922, 0.9922, 0.9255, 0.5804, 0.1725, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.1333, 0.4196, 0.4196, 0.4196, 0.1529, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFQe2Wgra0Cw",
        "colab_type": "text"
      },
      "source": [
        "Let's go with 3 epochs for now. So we will loop over epochs, and each epoch will loop over our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upcm62yTaLrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0655dd4d-d4da-4174-9e5b-25ed48384f2d"
      },
      "source": [
        "for epoch in range(EPOCHS): # 3 full passes over the data\n",
        "    for data in trainset:  # `data` is a batch of data\n",
        "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
        "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
        "        output = net(X.view(-1,28*28))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
        "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
        "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
        "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
        "    \n",
        "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1563, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0823, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XToVMAVFbFpE",
        "colab_type": "text"
      },
      "source": [
        "As we iterate, we get loss, which is an important metric, but we care about accuracy. So, how did we do? To test this, all we need to do is iterate over our test set, measuring for correctness by comparing output to target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opka-5htbMWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7971a1a0-71bd-447f-9cce-a1aec80cdebd"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testset:\n",
        "        X, y = data\n",
        "        output = net(X.view(-1,28*28))\n",
        "        #print(output)\n",
        "        for idx, i in enumerate(output):\n",
        "            #print(torch.argmax(i), y[idx])\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "print(\"Accuracy: \", correct/total)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu0uPqKccXKy",
        "colab_type": "text"
      },
      "source": [
        "하나씩 해봤을 때,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEMn3EDrcLSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2308454a-8342-4ecf-88b2-a672da788ca6"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0824, 0.2000, 0.5961, 0.7569, 0.5961, 0.5961,\n",
              "          0.5961, 0.5961, 0.5961, 0.2000, 0.0392, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.3216, 0.8745, 0.9137, 0.9882, 0.9922, 0.9882, 0.9922,\n",
              "          0.9882, 0.9922, 0.9882, 0.9922, 0.8314, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.5961, 0.9922, 0.9961, 0.9922, 0.9961, 0.9922, 0.9961,\n",
              "          0.9922, 0.9961, 0.9922, 0.9961, 0.9922, 0.4000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.3216, 0.9137, 0.9882, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922,\n",
              "          0.9882, 0.9922, 0.9882, 0.9922, 0.9882, 0.4000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.7176, 0.9961, 0.9922, 0.9961, 0.9922, 0.9961, 0.1961, 0.0000,\n",
              "          0.0000, 0.7569, 0.9922, 0.9961, 0.9922, 0.3216, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.2392, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922, 0.3569, 0.0000,\n",
              "          0.3216, 0.9137, 0.9882, 0.9922, 0.8314, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.3216, 0.9529, 0.9961, 0.9922, 0.9961, 0.9922, 0.4431,\n",
              "          0.9137, 0.9961, 0.9922, 0.9569, 0.1569, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.4784, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922,\n",
              "          0.9882, 0.9922, 0.9882, 0.4784, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.7569, 0.9922, 0.9961, 0.9922, 0.9961,\n",
              "          0.9922, 0.9961, 0.6745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.2784, 0.9882, 0.9922, 0.9882, 0.9922,\n",
              "          0.9882, 0.8353, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.1216, 0.9137, 0.9961, 0.9922, 0.9961,\n",
              "          0.9137, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.3608, 0.9882, 0.9922, 0.9882, 0.9922,\n",
              "          0.5922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.9961, 0.9922, 0.9961, 0.9922, 0.9961,\n",
              "          0.9922, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.4824, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922,\n",
              "          0.9882, 0.7176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.2824, 0.9922, 0.9961, 0.9922, 0.9961, 0.9922, 0.9961,\n",
              "          0.9922, 0.5569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.9137, 0.9882, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922,\n",
              "          0.9882, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.4000, 1.0000, 0.9922, 0.9961, 0.9922, 0.9961, 0.9922, 0.9961,\n",
              "          0.9137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.7176, 0.9922, 0.9882, 0.9922, 0.9882, 0.9922, 0.9882, 0.9137,\n",
              "          0.1961, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.7961, 1.0000, 0.9922, 0.9961, 0.9922, 0.9961, 0.9137, 0.4824,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.3176, 0.5922, 0.7529, 0.7529, 0.5922, 0.3569, 0.1176, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5OOyK5dcNTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "125c2064-5641-434b-bc6f-9536c78e454b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X[0].view(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmlv_1ZScSUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b319665e-d442-4693-9c9e-a6e0bd96f18d"
      },
      "source": [
        "print(torch.argmax(net(X[0].view(-1,784))[0]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN6Jrq6Scck3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx6thZL0MHiV",
        "colab_type": "text"
      },
      "source": [
        "## Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLZjozeQMGPH",
        "colab_type": "text"
      },
      "source": [
        "https://pythonprogramming.net/data-deep-learning-neural-network-pytorch/\n",
        "\n",
        "https://pythonprogramming.net/building-deep-learning-neural-network-pytorch/\n",
        "\n",
        "https://pythonprogramming.net/training-deep-learning-neural-network-pytorch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnkzapFIUEeE",
        "colab_type": "text"
      },
      "source": [
        "Thnx to youtube channel sentdex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElJCS4SqMG10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}